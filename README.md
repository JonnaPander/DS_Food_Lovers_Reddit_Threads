# Project 3: Web APIs & NLP

### Contents:
- [Problem Statement](#Problem-Statement)
- [Executive Summary](#Executive-Summary)
- [Data Sources](#Data-Sources)
- [Data Dictionary](#Data-Dictionary)
- [Conclusions/Recommendations](#Conclusions/Recommendations)

<a id=Problem Statement></a>
## Problem Statement

I have a collection food recipes, mostly Indian food dishes, I’ve been saving from different subreddit threads.  I plan on doing the Whole30 challenge, how can I take a bank of subreddit submissions collected from multiple sibreddit and dechiper which subreddit it came from? I want to make sure this amazing recipe I saved from subreddits is Whole30 approved.

<a id=Executive Summary></a>
## Executive Summary

I've developed a smart tool using data science that is geared toward Indian food lovers who want to know if the amazing recipe they just found complies with the stringent clean food standards of the now infamous Whole30 challenge.  The subreddits in question are IndianFood and whole30.  

This tool saves the Indian food lover the painstaking task of reading the books, the blog, and the dreaded food labels to finally get a grasp on which of their favorite dishes they can and can’t eat during the challenge.

This tool takes the text of a recipe description, i.e. reddit title, and runs algorithms to determine if the origin of the recipe is the Whole30 reddit thus meaning it is likely to be Whole30 approved. Pushshift API and Beautiful Soup were used to scrape and parse over 10,000 submission titles per thread for data processing.  Sklearn statistical modeling was used to generate predictions and evaluate logistic regression models and a NaiveBayes Multinomial model. The tool is based on the best of 3 models that were assessed. 

Several complex modeling algorithms in conjunction with Natural Language Processing techniques were assessed to find the perfect fit and the best model to make the prediction. The models included Logistic Regression with CountVectorizer, GridSearch with CountVectorizer, and Naive Bayes (Multinomial) with TFIDFVectorizer. The winning model was the Naive Bayes with a Training Accuracy Score of 96.15% and a Testing Accuracy Score of 93.52%. This beats the Baseline Accuracy of 48.23%. Based on the confusion matrix the Sensitivity (True Positive Rate) is 91.97% and the Specificity (True Negative Rate) is 94.96%.

<a id=Data Sources></a>
## Data Sources
[IndianFood](data/IndianFood.csv) <br>
[whole30](data/whole30.csv)

<a id=Data Dictionary></a>
## Data Dictionary
|Feature|Type|Dataset|Description|
|---|---|---|---|
|**Titles**|*object*|IndianFood|Title of subreddit submission|
|**Subreddit**|*object*|IndianFood|Name of the subreddit of origin|
|**Titles**|*object*|whole30|Title of subreddit submission|
|**Subreddit**|*object*|whole30|Name of the subreddit of origin|


<a id=Conclusions/Recommendations></a>
## Conclusions/Recommendations

The tool whittles down the bank of recipes to recipes that are likely to be Whole30 approved with an accuracy score of 91.97%. This is a great starting point for building an Indan food themed Whole30 compliant recipe collection. However, in the tools current state, if you are an Indian food lover who wants to take on the Whole30 challenge you should perform a secondary check of the recipes classifications generated by the tool to ensure they meet the stringent food restrictions of Whole30. Currently, the model is overfit to the training data. This tool could be marketable with further improvements such are regularization and further processing of data with natural language processing (NLP) techniques to make better predictions.  

